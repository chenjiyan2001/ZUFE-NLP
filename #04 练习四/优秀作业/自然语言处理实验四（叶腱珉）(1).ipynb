{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<center><font size=5 face=é›…é»‘> è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆå®éªŒå››ï¼‰ </font></center>  \n",
    "<br/>\n",
    "<center><font size=4 face=é›…é»‘> éšé©¬å°”å¯å¤«æ¨¡å‹åˆ†è¯ </font></center>  \n",
    "<br/>\n",
    "<center><font size=3 face=é›…é»‘> 18å¤§æ•°æ® å¶è…±ç‰ 180110950330 </font></center>  \n",
    "<br/>\n",
    "<center><font size=3 face=é›…é»‘> 2021 å¹´ 3 æœˆ 31 æ—¥ </font></center> \n",
    "<br/>  \n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»ƒä¹ è¦æ±‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åˆ©ç”¨MSRè¯­æ–™è®¡ç®—åˆå§‹çŠ¶æ€æ¦‚ç‡å‘é‡$\\pi$,çŠ¶æ€è½¬ç§»æ¦‚ç‡çŸ©é˜µ$A$å’Œå‘å°„æ¦‚ç‡çŸ©é˜µ$B$,æ„å»ºåˆ†è¯å™¨å¹¶è¿›è¡Œæ€§èƒ½è¯„æµ‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åˆ†è¯å™¨æ„å»º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å¯¼å…¥éœ€è¦çš„æ¨¡å—å’Œæ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re\n",
    "import os,sys\n",
    "from math import log\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "sighan05 = \"C:/Users/å¶è…±ç‰/Desktop/Natural Language Processing/å®éªŒäºŒ\\\n",
    "/ç¬¬äºŒå±Šå›½é™…ä¸­æ–‡åˆ†è¯è¯„æµ‹/icwb2-data/\"\n",
    "msr_train = os.path.join(sighan05,\"training\",\"msr_training.txt\")\n",
    "\n",
    "train_list = []      # è®­ç»ƒæ•°æ®\n",
    "with open(msr_train,'r') as train:\n",
    "    for i in train:\n",
    "        train_list.append(re.sub('\\n','',i).strip())\n",
    "while '' in train_list:\n",
    "    train_list.remove('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ„å»ºåºåˆ—æ ‡æ³¨å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_tagging(sentence):\n",
    "    sentence_list = sentence.split()\n",
    "    sentence_BMSE_list = [''.join(word) for word in [BMSE_tagging(word) for word in sentence_list]]\n",
    "    return ' '.join(sentence_BMSE_list)\n",
    "\n",
    "BMSE_dict = {1:['S'],2:['B','E']}\n",
    "def BMSE_tagging(word):\n",
    "    N = len(word)\n",
    "    try:\n",
    "        return BMSE_dict[N]\n",
    "    except:\n",
    "        if N < 1:\n",
    "            return \"ERROR\"\n",
    "        else:\n",
    "            return ['B']+['M']*(N-2)+['E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€œ  äººä»¬  å¸¸  è¯´  ç”Ÿæ´»  æ˜¯  ä¸€  éƒ¨  æ•™ç§‘ä¹¦  ï¼Œ  è€Œ  è¡€  ä¸  ç«  çš„  æˆ˜äº‰  æ›´  æ˜¯  ä¸å¯å¤šå¾—  çš„  æ•™ç§‘ä¹¦  ï¼Œ  å¥¹  ç¡®å®  æ˜¯  åå‰¯å…¶å®  çš„  â€˜  æˆ‘  çš„  å¤§å­¦  â€™  ã€‚ \n",
      "\n",
      "\n",
      " S BE S S BE S S S BME S S S S S S BE S S BMME S BME S S BE S BMME S S S S BE S S\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•åºåˆ—æ ‡æ³¨ç»“æœ\n",
    "msr_BMSE_list = [sentence_tagging(sentence) for sentence in train_list]\n",
    "\n",
    "print(train_list[0],'\\n')\n",
    "print(\"\\n\",msr_BMSE_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åˆ©ç”¨MSRè¯­æ–™è®¡ç®—åˆå§‹çŠ¶æ€æ¦‚ç‡å‘é‡ ğœ‹ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bmse_freq(BMSE_frequency):\n",
    "    prob_list = {}\n",
    "    sum1 = sum(BMSE_frequency.values())\n",
    "    for key,value in BMSE_frequency.items():\n",
    "        prob_list[key]=log(value/sum1)\n",
    "    return prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S': -1.1894065754192553,\n",
       " 'B': -0.3629831561081316,\n",
       " 'M': -3.14e+100,\n",
       " 'E': -3.14e+100}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æ¦‚ç‡å€¼éƒ½æ˜¯å–å¯¹æ•°ä¹‹åçš„ç»“æœ\n",
    "MIN_FLOAT = -3.14e100\n",
    "\n",
    "# åˆ©ç”¨MSRè¯­æ–™çš„æ ‡æ³¨åºåˆ—ï¼Œç»Ÿè®¡BMSEé¢‘æ•°ï¼Œè®¡ç®—åˆå§‹çŠ¶æ€æ¦‚ç‡å‘é‡\n",
    "msr_prob_start = calc_bmse_freq( Counter([i[0:1] for i in msr_BMSE_list]))\n",
    "# ç”±äºåˆå§‹çŠ¶æ€åªèƒ½æ˜¯Bæˆ–è€…Sï¼Œæ•…å°†Må’ŒEçš„åˆå§‹çŠ¶æ€æ¦‚ç‡è®¾ç½®ä¸ºå¾ˆå°\n",
    "msr_prob_start['M'] = MIN_FLOAT\n",
    "msr_prob_start['E'] = MIN_FLOAT\n",
    "\n",
    "# åˆå§‹çŠ¶æ€æ¦‚ç‡å‘é‡\n",
    "msr_prob_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  åˆ©ç”¨MSRè¯­æ–™è®¡ç®—çŠ¶æ€è½¬ç§»æ¦‚ç‡çŸ©é˜µ ğ´ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'SB': 600115,\n",
       "         'BE': 1039906,\n",
       "         'ES': 659674,\n",
       "         'SS': 427204,\n",
       "         'BM': 215149,\n",
       "         'ME': 215149,\n",
       "         'MM': 211874,\n",
       "         'EB': 594480})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# åˆ é™¤åŸåºåˆ—æ ‡æ³¨å¥å­ä¸­çš„ç©ºæ ¼\n",
    "msr_BMSE_list1 = [re.sub(\" \",\"\",sentence) for sentence in msr_BMSE_list]\n",
    "\n",
    "# è®¡ç®—æ‰€æœ‰å‰åä¸¤åºåˆ—ç»„åˆçš„é¢‘ç‡\n",
    "msr_trans_list = [sentence[i:i+2] for sentence in msr_BMSE_list1 for i in range(len(sentence)-1)]\n",
    "msr_trans_count = Counter(msr_trans_list)\n",
    "\n",
    "# ç»Ÿè®¡åºåˆ—é¢‘æ•°å¹¶ç”Ÿæˆå­—å…¸\n",
    "msr_trans_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'S': {'B': -0.5375864716182832, 'S': -0.8774461242373575},\n",
       " 'B': {'E': -0.18804907187170708, 'M': -1.763603863953054},\n",
       " 'E': {'S': -0.6424707470719607, 'B': -0.7465294468210316},\n",
       " 'M': {'E': -0.6855070645928693, 'M': -0.7008461175870558}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ç»Ÿè®¡åºåˆ—é¢‘æ•°ç”Ÿæˆå­—å…¸åè®¡ç®—è½¬ç§»æ¦‚ç‡çŸ©é˜µ\n",
    "def calc_prob_trans(BMSE_frequency):\n",
    "    prob_list = {}\n",
    "    BMSE_frequency.keys()\n",
    "    for key,value in BMSE_frequency.items():\n",
    "        if key[0] not in BMSE_frequency.keys():\n",
    "            prob_list.setdefault(key[0],{})\n",
    "        prob_list[key[0]][key[1]] = value\n",
    "    for key in prob_list.keys():\n",
    "        prob_list[key] = calc_bmse_freq(prob_list[key])\n",
    "    return prob_list\n",
    "\n",
    "# çŠ¶æ€è½¬ç§»æ¦‚ç‡çŸ©é˜µ\n",
    "msr_prob_trans = calc_prob_trans(Counter(msr_trans_count))\n",
    "msr_prob_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åˆ©ç”¨MSRè¯­æ–™è®¡ç®—å‘å°„æ¦‚ç‡çŸ©é˜µ ğµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ„å»ºå•å­—åˆ—è¡¨\n",
    "msr_words_list = [re.sub(\" \",\"\",sentence) for sentence in train_list]\n",
    "msr_words_list = list(''.join(msr_words_list))\n",
    "# æ„å»ºå•è¯åºåˆ—è¡¨\n",
    "msr_BMSE_words_list = [re.sub(\" \",\"\",sentence) for sentence in msr_BMSE_list]\n",
    "msr_BMSE_words_list = list(''.join(msr_BMSE_words_list))\n",
    "# å•å­—å’Œå•è¯åºåˆ—æ‹¼æ¥ç»„åˆ\n",
    "combineList = list(zip(msr_BMSE_words_list,msr_words_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['B', 'M', 'S', 'E'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('äºº', -4.868080392268559),\n",
       " ('ç”Ÿ', -5.37793919851509),\n",
       " ('æ•™', -5.731291675852302),\n",
       " ('æˆ˜', -6.44178749474686),\n",
       " ('ä¸', -4.591680504132731)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msr_prob_emit = {}  # å‘å°„æ¦‚ç‡çŸ©é˜µ\n",
    "BMSE_list = list(\"BMSE\")\n",
    "for f in BMSE_list:\n",
    "    # æ„å»ºäºŒçº§å­—å…¸\n",
    "    msr_prob_emit.setdefault(f,{})\n",
    "    # ç­›é€‰å‡ºæŸä¸ªè¯åºçš„æ‰€æœ‰å‘å°„ç»“æœ\n",
    "    combineList_temp = [zip_i for zip_i in combineList if zip_i[0] == f]\n",
    "    # ç»Ÿè®¡è¯åºé¢‘æ•°ï¼Œå¹¶è®¡ç®—å‘å°„æ¦‚ç‡\n",
    "    calc_emit = calc_bmse_freq(dict(Counter(combineList_temp)))\n",
    "    for key,value in calc_emit.items():\n",
    "        # å‘å°„æ¦‚ç‡çŸ©é˜µå†™å…¥\n",
    "        msr_prob_emit[key[0]][key[1]] = value\n",
    "\n",
    "# ä¸€çº§å­—å…¸keys\n",
    "print(msr_prob_emit.keys())\n",
    "# éƒ¨åˆ†ç»“æœæ˜¾ç¤ºï¼Œå¦‚å–åºåˆ—æ ‡æ³¨ä¸ºBçš„å‰äº”ä¸ªè¯çš„å‘å°„æ¦‚ç‡ç»“æœ\n",
    "list(msr_prob_emit['B'].items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ„å»ºåˆ©ç”¨msrè¯­æ–™è®¡ç®—å¾—åˆ°åˆå§‹å‚æ•°çš„HMMæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrevStatus = {\n",
    "    'B': 'ES',\n",
    "    'M': 'MB',\n",
    "    'S': 'SE',\n",
    "    'E': 'BM'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-30.294867244593323, ['B', 'E', 'S', 'B', 'E'])\n"
     ]
    }
   ],
   "source": [
    "def viterbi(obs, states, start_p, trans_p, emit_p):\n",
    "    V = [{}]  # tabular\n",
    "    path = {}\n",
    "    for y in states:  # init\n",
    "        V[0][y] = start_p[y] + emit_p[y].get(obs[0], MIN_FLOAT)\n",
    "        path[y] = [y]\n",
    "\n",
    "    for t in range(1, len(obs)):\n",
    "        V.append({})\n",
    "        newpath = {}\n",
    "        for y in states:\n",
    "            em_p = emit_p[y].get(obs[t], MIN_FLOAT)\n",
    "            (prob, state) = max(\n",
    "                [(V[t - 1][y0] + trans_p[y0].get(y, MIN_FLOAT) + em_p, y0) for y0 in PrevStatus[y]])\n",
    "            V[t][y] = prob\n",
    "            newpath[y] = path[state] + [y]\n",
    "        path = newpath\n",
    "\n",
    "    (prob, state) = max((V[len(obs) - 1][y], y) for y in 'ES')\n",
    "\n",
    "    return (prob, path[state])\n",
    "\n",
    "sentence = \"å•†å“å’ŒæœåŠ¡\"\n",
    "print(viterbi(sentence, \"BMES\", msr_prob_start, msr_prob_trans, msr_prob_emit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['å•†å“', 'å’Œ', 'æœåŠ¡']\n"
     ]
    }
   ],
   "source": [
    "def __cut(sentence):\n",
    "    global emit_P\n",
    "    prob, pos_list = viterbi(sentence, 'BMES', msr_prob_start, msr_prob_trans, msr_prob_emit)\n",
    "    begin, nexti = 0, 0\n",
    "    # print pos_list, sentence\n",
    "    for i, char in enumerate(sentence):\n",
    "        pos = pos_list[i]\n",
    "        if pos == 'B':\n",
    "            begin = i\n",
    "        elif pos == 'E':\n",
    "            yield sentence[begin:i + 1]\n",
    "            nexti = i + 1\n",
    "        elif pos == 'S':\n",
    "            yield char\n",
    "            nexti = i + 1\n",
    "    if nexti < len(sentence):\n",
    "        yield sentence[nexti:]\n",
    "print(list(__cut(sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€§èƒ½è¯„æµ‹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åŠ è½½è¯å…¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dictionary(dict_file):\n",
    "    \"\"\"\n",
    "    åŠ è½½è¯åº“\n",
    "    :return: ä¸€ä¸ªsetå½¢å¼çš„è¯åº“\n",
    "    \"\"\"\n",
    "    fr = open(dict_file,encoding=\"utf-8\")\n",
    "    word_list = [item.strip().split(\"\\t\")[0] for item in fr]\n",
    "    return set(word_list)    # ä»¥é›†åˆå½¢å¼åŠ è½½ï¼Œå®ç°å»é‡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ€§èƒ½æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_region(segmentation: str) -> list:\n",
    "    \"\"\"\n",
    "    å°†åˆ†è¯ç»“æœè½¬æ¢ä¸ºåŒºé—´\n",
    "    :param segmentation: å•†å“ å’Œ æœåŠ¡\n",
    "    :return: [(0, 2), (2, 3), (3, 5)]\n",
    "    \"\"\"\n",
    "    region = []\n",
    "    start = 0\n",
    "    for word in re.compile(\"\\\\s+\").split(segmentation.strip()):\n",
    "        end = start + len(word)\n",
    "        region.append((start, end)) \n",
    "        start = end\n",
    "    return region\n",
    "\n",
    "\n",
    "def prf(gold: str, pred: str, dic) -> tuple:\n",
    "    \"\"\"\n",
    "    è®¡ç®—Pã€Rã€F1\n",
    "    :param gold: æ ‡å‡†ç­”æ¡ˆæ–‡ä»¶ï¼Œæ¯”å¦‚â€œå•†å“ å’Œ æœåŠ¡â€\n",
    "    :param pred: åˆ†è¯ç»“æœæ–‡ä»¶ï¼Œæ¯”å¦‚â€œå•†å“ å’Œæœ åŠ¡â€\n",
    "    :param dic: è¯å…¸\n",
    "    :return: (P, R, F1, OOV_R, IV_R)\n",
    "    \"\"\"\n",
    "    A_size, B_size, A_cap_B_size, OOV, IV, OOV_R, IV_R = 0, 0, 0, 0, 0, 0, 0\n",
    "    with open(gold,encoding=\"utf-8\") as gd, open(pred,encoding=\"utf-8\") as pd:\n",
    "        for g, p in zip(gd, pd):\n",
    "            A, B = set(to_region(g)), set(to_region(p))\n",
    "            A_size += len(A)\n",
    "            B_size += len(B)\n",
    "            A_cap_B_size += len(A & B)\n",
    "            text = re.sub(\"\\\\s+\", \"\", g)\n",
    "            for (start, end) in A:\n",
    "                word = text[start: end]\n",
    "                if word in dic:\n",
    "                    IV += 1\n",
    "                else:\n",
    "                    OOV += 1\n",
    "\n",
    "            for (start, end) in A & B:\n",
    "                word = text[start: end]\n",
    "                if word in dic:\n",
    "                    IV_R += 1\n",
    "                else:\n",
    "                    OOV_R += 1\n",
    "    p, r = A_cap_B_size / B_size * 100, A_cap_B_size / A_size * 100\n",
    "    return p, r, 2 * p * r / (p + r), OOV_R / OOV * 100, IV_R / IV * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "msr_output = os.path.join(sighan05, 'testing', 'msr_output.txt')\n",
    "msr_gold = os.path.join(sighan05, 'gold', 'msr_test_gold.utf8')\n",
    "\n",
    "word_dict = load_dictionary(\"C:/Users/å¶è…±ç‰/Desktop/Natural Language Processing/\\\n",
    "å®éªŒäºŒ/SogouW/Freq/SogouLabDic.dic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P:78.03 R:80.05 F1:79.03 OOV-R:77.23 IV-R:82.81\n",
      "runtime:1.3085010051727295s\n"
     ]
    }
   ],
   "source": [
    "with open(msr_gold, encoding=\"utf-8\") as test, open(msr_output, 'w', encoding=\"utf-8\") as output:\n",
    "    start = time.time()\n",
    "    for line in test:\n",
    "        output.write(\"  \".join(__cut(re.sub(\"\\\\s+\", \"\", line))))\n",
    "        output.write(\"\\n\")\n",
    "    runtime = time.time()-start\n",
    "print(\"P:%.2f R:%.2f F1:%.2f OOV-R:%.2f IV-R:%.2f\" % prf(msr_gold, msr_output, word_dict))\n",
    "print('runtime:{}s'.format(runtime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åˆ†è¯ç»“æœè¾“å‡ºä¿å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(msr_gold, encoding=\"utf-8\") as test:\n",
    "    pos_list_out = []\n",
    "    cut_out = []\n",
    "    for line in test:\n",
    "        # å°†æ¯ä¸ªå­—çš„æ ‡æ³¨åºåˆ—è¾“å‡ºä¿å­˜ï¼Œæ¯ä¸ªå¥å­ä»¥ç©ºå…ƒç´ éš”å¼€\n",
    "        prob, pos_list = viterbi(re.sub(\"\\\\s+\", \"\", line), 'BMES', msr_prob_start, msr_prob_trans, msr_prob_emit)\n",
    "        for w1 in pos_list:\n",
    "            pos_list_out.append(w1)\n",
    "        pos_list_out.append(\"\")\n",
    "        # å°†æ¯ä¸ªå¥å­æ‹†åˆ†æˆå•å­—ä¿å­˜\n",
    "        word_split = re.sub(\"\\\\s+\",\"\",line)\n",
    "        word_split = list(''.join(word_split))\n",
    "        for w2 in word_split:\n",
    "            cut_out.append(w2)\n",
    "        cut_out.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°†å•å­—å’Œæ ‡æ³¨åºåˆ—åˆ—è¡¨åˆæˆä¸€ä¸ªæ•°æ®æ¡†\n",
    "segmentation_out = pd.DataFrame({\"word\":cut_out,\"tagging\":pos_list_out})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tagging</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>æ‰¬</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>å¸†</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>è¿œ</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ä¸œ</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>åš</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188335</th>\n",
       "      <td>çš„</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188336</th>\n",
       "      <td>å¯¹</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188337</th>\n",
       "      <td>è¯</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188338</th>\n",
       "      <td>ã€‚</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188339</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188340 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word tagging\n",
       "0         æ‰¬       B\n",
       "1         å¸†       E\n",
       "2         è¿œ       B\n",
       "3         ä¸œ       E\n",
       "4         åš       S\n",
       "...     ...     ...\n",
       "188335    çš„       S\n",
       "188336    å¯¹       B\n",
       "188337    è¯       E\n",
       "188338    ã€‚       S\n",
       "188339             \n",
       "\n",
       "[188340 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentation_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å°†æ•°æ®æ¡†ä¿å­˜ä¸ºtxtæ–‡ä»¶\n",
    "segmentation_out.to_csv(\"C:/Users/å¶è…±ç‰/Desktop/Natural Language Processing\\\n",
    "/å®éªŒå››/segmentation_result.txt\",sep='\\t',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
